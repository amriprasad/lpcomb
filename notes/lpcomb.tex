\documentclass{amsbook}
\usepackage{amssymb,hyperref}
\newcommand{\vv}{\mathbf v}
\newcommand{\xx}{\mathbf x}
\newcommand{\yy}{\mathbf y}
\newcommand{\cc}{\mathbf c}
\newcommand{\bb}{\mathbf b}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\RR}{\mathbf R}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{remark}[theorem]{Remark}
\begin{document}
\title{Linear Programming in Combinatorics}
\author{Amritanshu Prasad}
\address{The Institute of Mathematical Sciences, Chennai.}
\address{Homi Bhabha National Institute, Mumbai.}
\email{amri@imsc.res.in}
\date{\today}
\maketitle
\chapter{Introduction to Linear Programming}
\label{cha:intro-lp}
\section{Feasibility and Optimization}
\label{sec:feas-opt}
A \emph{linear program in equational form} consists of a set of variables $\xx=(x_1,\dotsc,x_n)$, an $m\times n$ matrix $A$ with real entries, a bound vector $\bb=(b_1,\dotsc,b_m)$, and an objective vector $\cc = (c_1,\dotsc,c_n)$.
The \emph{linear program} is the problem:
\begin{equation}
  \tag{LP}
  \label{eq:lp-problem}
  \text{maximize $\cc^T\xx$ subject to $\xx\geq 0$ and $A\xx=\bb$}.
\end{equation}
The set
\begin{displaymath}
  P(A,\bb) = \{\xx\in \RR^n\mid \xx\geq 0,\;A\xx=\bb\}
\end{displaymath}
is called the polytope of all \emph{feasible solutions} to \eqref{eq:lp-problem}.
The function $\xx\mapsto \cc^T\xx$ is called the \emph{objective function}.
An \emph{optimal solution} is a vector $\xx_0\in P(A,\bb)$ such that $\cc^T\xx\leq \cc^T\xx_0$ for every $\xx\in P(A,\bb)$.
Sometimes we will only be interested in the set $P(A,\bb)$ of feasible solutions, which does not depend on the objective vector.

Assume that $\bb$ lies in the column space of $A$ (for otherwise, we would have $P(A,\bb)=\emptyset$), and that the rows of $A$ are linearly independent (if not, we could discard redundant rows to achieve this).
For a subset $B\subset [n]$, let $A_B$ denote the submatrix of $A$ consisting of columns from $B$.
We say that $B$ is a \emph{basic set} if $B$ has $m$ elements and $A_B$ has rank $m$.
For $\xx\in \RR^n$ define:
\begin{displaymath}
  \supp(\xx)=\{1\leq j\leq n\mid x_j\neq 0\}.
\end{displaymath}
\begin{definition}
  [Basic feasible solution]
  A \emph{basic feasible solution} to \eqref{eq:lp-problem} is a feasible solution $\xx\in P(A,\bb)$ such that $\supp(\xx)$ is contained in a basic set.
\end{definition}
Clearly, a feasible solution $\xx$ is basic if and only if the submatrix $A_{\supp(\xx)}$ has linearly independent columns.
\begin{example}[The Birkhoff polytope]
  \label{example:birkhoff}
  Take $n=d^2$, indexing the $d^2$ variables as $\xx=(x_{ij})_{1\leq i,j\leq d}$, a square array of size $d$.
  As constraints, say that the row sums and column sums of $\xx$ are all equal to $1$, i.e.,
  \begin{align}
    \tag{R}
    \label{eq:row-sum-cons}
    \sum_j x_{ij} &= 1 \text{ for } j=1,\dotsc,d,\\
    \tag{C}
    \label{eq:col-sum-cons}
    \sum_i x_{ij} &= 1 \text{ for } j=1,\dotsc,d.
  \end{align}
  These $2d$ constraints are not independent--the sum of the row sum constraints \eqref{eq:row-sum-cons} is equal to the sum of the column sum constraints~\eqref{eq:col-sum-cons}; it is the constraint that all entries of the matrix add up to $d$.
  Removing, for instance, the last column constraint gives a $(2d-1)\times d^2$ matrix $A$ of rank $2d-1$.

  When $d=2$, the constraints can be expressed in matrix form as
  \begin{equation}
    \label{eq:birkhoff2}
    \begin{pmatrix}
      1 & 1 & 0 & 0\\
      0 & 0 & 1 & 1\\
      1 & 0 & 1 & 0
    \end{pmatrix}
    \begin{pmatrix}
      x_{11}\\x_{12}\\x_{21}\\x_{22}
    \end{pmatrix}
    =
    \begin{pmatrix}
     1\\1\\1
    \end{pmatrix}.
  \end{equation}
  Every submatrix of $A$ with three columns is non-singular.
  Thus there are four possible basic sets.
  It is easy to see, however, that there are only two basic solutions, given by the permutation matrices:
  \begin{displaymath}
    \begin{pmatrix}
      x_{11} & x_{12}\\
      x_{21} & x_{22}
    \end{pmatrix}
    =
    \begin{pmatrix}
      1 & 0\\
      0 & 1
    \end{pmatrix}, \text{ or }
    \begin{pmatrix}
      x_{11} & x_{12}\\
      x_{21} & x_{22}
    \end{pmatrix}
    =
    \begin{pmatrix}
      0 & 1\\
      1 & 0
    \end{pmatrix}.
  \end{displaymath}
  \begin{exercise}
    Let $B$ be a basic subset of $[d]\times [d]$.
    By definition, $B$ has cadrinality $2d-1$.
    Given $B$, define a bipartite graph $\Gamma_B$ on the set $\{1,2,3,1',2',3'\}$ by joining $i$ to $j'$ if $(i,j)\in B$.
    Show that $\Gamma_B$ is a spanning tree for the complete bipartite graph $K_{3,3}$.
    Show that this construction gives rise to a bijection from the set of basic subsets of $[d]\times[d]$ onto the set of spanning trees of $K_{n,n}$.
  \end{exercise}
  Let $\sigma\in S_d$ and suppose $\xx$ is the permutation matrix $x_{ij}=\delta_{i\sigma(i)}$.
  Then $\supp(\xx)=\{(i,\sigma_i)\mid i\in [d]\}$.
  The first $d$ rows of the corresponding column vectors of $A$ are just the coordinate vectors of $\RR^d$.
  Therefore each permutation matrix is a basic feasible solution.
  Which spanning trees does it correspond to?
\end{example}
\begin{lemma}
  \label{lemma:unique-for-B}
  For each basic subset $B\subset [d]$, there exists at most one basic feasible solution $\xx$ with $\supp(\xx)\subset B$.
\end{lemma}
In the situation described in the preceding lemma, we say that \emph{$\xx$ is the basic solution corresponding to $B$}.
\begin{proof}
  Let $\xx_B$ denote the vector $(x_i)_{i\in B}$.
  The matrix $A_B$ is non-singular, so the equation $A_B\xx_B=\bb$ has at most one solution.
  Solutions $\xx$ of $A\xx=\bb$ with $\supp(\xx)\subset B$ are in bijection with solutions of $A_B\xx_B=\bb$ (set $x_j=0$ for $j\notin B$ to get $\xx$ from $\xx_B$).
  Therefore $A\xx=\bb$ also has at most one solution.
\end{proof}
\begin{remark}
  The same basic feasible solution could be obtained from different basic sets.
  For example, each basic solution for \eqref{eq:birkhoff2} corresponds to two basic sets.
  Also not every basic set $B$ admits a basic feasible solution.
  For example, in Example~\ref{example:birkhoff}, $B=\{(1,1),(1,2),(1,3),(2,1),(3,1)\}$ is a basic set with no feasible solution.
\end{remark}
\begin{theorem}
  [Existence of basic optimal solutions]
  \label{theorem:existence-of-basic-solutions}
  For a linear program in equational form:
  \begin{displaymath}
    \text{maximize $\cc^t\xx$ subject to $A\xx=\bb$, $\xx\geq 0$}
  \end{displaymath}
  if there is at least one feasible solution, and the objective function is bounded above on $P(A,\bb)$, then there exists at least one optimal solution.
  Among the optimal solutions there is at least one basic solution.
\end{theorem}
\begin{proof}
  We claim that, for any feasible solution $\xx_0$, there exists a basic feasible solution $\xx$ with $\cc^T\xx\geq \cc^T\xx_0$.
  This implies that an optimal solution, if it exists, will be basic.
  Suppose $\xx$ is a feasible solution.
  Among all feasible solutions $\xx$ with $\cc^T\xx\geq \cc^T\xx_0$ choose one with support of minimal cardinality and call it $\tilde \xx$.
  We will show that $A_{\supp(\tilde\xx)}$ has linearly independent columns, so that $\tilde\xx$ is basic.
  
  Suppose this is not the case.
  Then there exists a vector $\yy\in \RR^n$ with $\supp(\yy)\subset \supp(\xx)$ such that $A\yy=0$.
  Replacing $\yy$ by $-\yy$ if necessary, assume that $\cc^T\yy\geq 0$.

  We claim that we may further assume that $\yy$ has at least one \emph{negative} coordinate.
  Suppose that all the coordinates of $\yy$ are non-negative.
  If $\cc^T\yy=0$, then we can replace $\yy$ with $-\yy$.
  If $\cc^T\yy>0$ and all coordinates of $\yy$ are positive, then $\tilde\xx+t\yy$ is a feasible solution for all $t>0$.
  The objective function $\cc^T(\tilde\xx+t\yy)$ grows unboundedly as $t$ grows, contradicting its boundedness.

  Thus $\yy$ has at least one negative coordinate, hence it is possible to choose a value $t>0$ such that $\tilde\xx+t\yy$ is a feasible solution with $\supp(\tilde\xx+t\yy)\subsetneqq \supp(\tilde\xx)$.
  Since $\cc^T\yy\geq 0$, we have $\cc^T(\tilde\xx+t\yy)\geq \cc^T\tilde\xx$ and $\supp(\tilde\xx+t\yy)$.
  This contradicts the minimality condition on the cardinality of $\supp(\tilde\xx)$.

  The set of basic feasible solutions is finite.
  The element of this set that maximizes the objective function must therefore be an optimal solution.
\end{proof}
\begin{definition}
  [Vertex]
  \label{definition:vertex}
  Let $P\subset \RR^n$ be convex closed set.
  An element $\vv\in P$ is said to be a \emph{vertex} of $P$ if there exists $\cc\in \RR^n$ such that $\cc^T\xx$ attains its maximum \emph{uniquely} at $\vv$.
\end{definition}
Theorem~\ref{theorem:existence-of-basic-solutions} says that every vertex of $P(A,\bb)$ is a basic feasible solution.
The converse is also true:
\begin{theorem}
  The basic feasible solutions to \eqref{eq:lp-problem} are precisely the vertices of $P(A,\bb)$.
\end{theorem}
\begin{proof}
  Let $B\subset [n]$ be a basic subset $\vv$ be the basic feasible solution to \eqref{eq:lp-problem} with respect to $B$.
  Define $\cc$ to be the vector with $c_j=0$ for $j\in B$, and $c_j=-1$ (or any strictly negative number) otherwise.
  Then $\cc^T\vv=0$, and by Lemma~\ref{lemma:unique-for-B}, $\cc^T\xx<0$ for every $\xx\in P(A,\bb)$ different from $\xx_0$.
\end{proof}
\begin{definition}
  [General form of a linear program]
  A more general form of a linear program involves linear inequalities and equalities.
  As before take $A$ to be an $m\times n$ matrix with real entries, $\bb\in \RR^m$, and $\cc\in \RR^n$.
  A general linear program has the form:
  \begin{equation}
    \label{eq:general-lp}
    \tag{GLP}
    \text{optimize $\cc^T\xx$ subject to }a_{i1}x_1+\dotsb + a_{in}x_n\; R_i\; b_i \text{ for }i=1,\dotsc,m,
  \end{equation}
  where $R_i$ is one of the three symbols $\leq$, $\geq$, and $=$, and the word optimize is replaced by either maximize, or minimize.
  A basic feasible solution is one that is defined by equalities in $n$ linearly independent constraints (which could be equality or inequality to begin with).
\end{definition}
\begin{example}
  [Standard equational form of the simplex]
  Consider the linear program in $n$ variables with just one linear equation:
  \begin{displaymath}
    \xx\geq 0;\; x_1+\dotsb+x_n=1.
  \end{displaymath}
  The matrix $A$ in this case has a single row, and rank one.
  The polytope $P(A,1)$ is called the standard $(n-1)$-simplex.
  Every singleton subset of $[n]$ is basic.
  The basic solution corresponding to $B=\{j\}$ is the $i$th coordinate vector $e_j$.
  Given an objective vector $\cc\in \RR^n$, the optimal solution is $e_j$ where $j$ is any of the indices for which $c_j$ is maximal among the coordinates of $\cc$.
\end{example}
\begin{example}
  The cube can be defined by the inequalities:
  \begin{displaymath}
    0\leq x_i \leq 1, \text{ for } i=1,2,3.
  \end{displaymath}
  The inequality $x_i\leq 1$ can be turned into an equality by introducing \emph{slack variables} $y_i$, and writing:
  \begin{displaymath}
    x_i\geq 0,\;y_i\geq 0,\;x_i+y_i\leq 1 \text{ for }i=1,2,3.
  \end{displaymath}
  The linear program in equational form is equivalent to the original, more general one, in the sense that there is a bijection amongst their feasible solutions that maps vertices to vertices (why?).
  What are the basic subsets? What are the basic feasible solutions?
\end{example}
\begin{exercise}
  [The simplex in terms of inequalities]
  The $n$-simplex can also be expressed in terms of inequalities:
  \begin{displaymath}
    \Delta_n = \{(x_1,\dotsc,x_n)\mid 0\leq x_1\leq x_2 \leq \dotsb x_n\leq 1\}.
  \end{displaymath}
  Rewrite this in equational form.
  Determine the basic sets and basic solutions.
\end{exercise}
\begin{exercise}
  Express the hyperoctahedron:
  \begin{displaymath}
    H_n = \{\xx\mid -1\leq x_1+\dotsb+x_n\leq 1\}
  \end{displaymath}
  in equational form.
\end{exercise}

\section{The Simplex Method}
\label{sec:simplex-method}

The simplex method begins with a basic set $B$ for which there exists a basic feasible solution.
Let $\bar B=[n]-B$, the complement of $B$ in $[n]$.
Using the relations imposed by $A\xx=\bb$, each of the basic variables $x_j$, $j\in B$, can be expressed in terms of the non-basic variables $x_j$, $j\in \bar B$.
Using this, the objective function can also be expressed in terms of the non-basic variables.

To do this explicitly, note that the system of equations $A\xx=\bb$ can be rearranged as:
\begin{equation}
  \label{eq:basic_from_nonbasic}
  A_B\xx_B = \bb-A_{\bar B}\xx_{\bar B}.
\end{equation}
Here $\xx_B\in\RR^m$ and $\xx_{\bar B}\in\RR^{m-n}$ are vectors whose coordinates are those coordinates of $\xx$ whose indices lie in $B$ and $\bar B$ respectively. 
Since $A_B$ is invertible, the basic variables can be expressed in terms of the non-basic ones:
\begin{displaymath}
  \xx_B = A_B^{-1}(\bb-A_{\bar B}\xx_{\bar B}).
\end{displaymath}
Indeed, the basic feasible solution is computed by setting $\xx_{\bar B}=0$ in the above equation.
If $A_B^{-1}\bb\geq 0$, then it is the basic feasible solution corresponding to $B$.
Othewise there is no basic feasible solution corresponding to $B$.
Since each basic variable is expressed in terms of the non-basic variables in \eqref{eq:basic_from_nonbasic}, the objective function can be expressed in terms of the non-basic variables only:
\begin{displaymath}
  \cc^T\xx = \cc_B^T\xx_B + \cc_{\bar B}^T\xx_{\bar B} = \cc^T_BA_B^{-1}(\bb-A_{\bar B}\xx_{\bar B}) + \cc^T_{\bar B}\xx_{\bar B}.
\end{displaymath}

This data is represented in terms of a \emph{simplex tableau}:
\begin{equation}
  \tag{T}
  \label{eq:tableau}
  \begin{matrix}
    \xx_B & = & \mathbf d - D\xx_{\bar B}\\
    \hline
    \cc^T\xx & = & e - \mathbf e^T \xx_{\bar B}.
  \end{matrix}
\end{equation}
Here:
\begin{align*}
  \mathbf d & = A_B^{-1}\bb\\
  D & = A_B^{-1}A_{\bar B}\\
  e & = \cc_B^T \mathbf d\\
  \mathbf e^T & = \cc_B^TD - \cc_{\bar B}^T.
\end{align*}
There are $m$ equations in \eqref{eq:tableau}, one for each basic variable, expressing it as an affine linear combination of the basic variables.
The last line of (\ref{eq:tableau}) is simply the objective function expressed in terms of the basic variables.
The information contained in \eqref{eq:tableau} is equivalent to the information in \eqref{eq:lp-problem}.
But \eqref{eq:tableau} gives a sort-of parametrization of $P(A,b)$.
\begin{theorem}
  \label{theorem:basic-parametrization}
  For every basic subset $B\subset [n]$ in the linear program \eqref{eq:lp-problem},
  \begin{equation}
    \tag{$*$}
    \label{equation:tableau-par}
    P(A,\bb) = \{\xx\in \RR^n\mid \xx\geq 0,\; \xx_B=A_B^{-1}(\bb-A_{\bar B}\xx_{\bar B}),\;\xx_{\bar B}\geq 0\}.
  \end{equation}
\end{theorem}
\begin{proof}
  The conditions $A\xx=\bb$ and $\xx_B=A_B^{-1}(\bb-A_{\bar\xx}x_{\bar B})$ are equivalent.
\end{proof}
\begin{example}
  \label{example:birkhoof2-tableau}
  Consider the Birkhoff polytope (Example~\ref{example:birkhoff}) for $d=3$.
  For convenience we abbreviate the variable indices $(i,j)$ to $ij$.
  The matrix $A$ has columns indexed by pairs in $[d]\times [d]$ written in increasing lexicographic order:
  \begin{displaymath}
    A =
    \begin{pmatrix}
      1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
      0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0\\
      0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1\\
      1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0\\
      0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0\\
    \end{pmatrix}
  \end{displaymath}
  Fix as objective function $x_{11}+x_{22}+x_{33}$.
  A basic subset is $B=\{11,12,13,22,31\}$ with basic solution given by $x_{13}=x_{22}=x_{31}=1$, and all other coordinates zero.
  The corresponding simplex tableau is:
  \begin{displaymath}
    \begin{matrix}
      x_{11} & = & -x_{21} +x_{32}+x_{33}\\
      x_{12} & = & x_{21}+x_{23}-x_{32}\\
      x_{13} & = & 1-x_{23}-x_{33}\\
      x_{22} & = & 1-x_{21} -x_{23}\\
      x_{31} & = & 1-x_{32}-x_{33}\\
      \hline
      \cc^T\xx & = & 1-2x_{21}-x_{23}+x_{32}+2x_{33}.
    \end{matrix}
  \end{displaymath}
  In the above example, the objective function can be increased by increasing $x_{32}$ or $x_{33}$, the variables with positive coefficients in the last row of the tableau.
  However, this increase should respect the constraints that all the variables are non-negative.
  The condition $x_{12}\geq 0$ (using the second equation, and leaving the values of $x_{21}$ and $x_{23}$ unchanged at $0$) gives $x_{32}\leq 0$.
  Therefore, it is not feasible to increase $x_{32}$.
  However, it is feasible to increase $x_{33}$.
  The conditions $x_{13}\geq 0$ and $x_{31}\geq 0$ give $x_{33}\leq 1$.
  So we set $x_{33}=1$, and recalculate all the basic variables, getting $x_{11}=x_{22}=x_{33}=1$, and all other variables $0$.
  We move $x_{33}$ to the set of basic variables, and move $x_{13}$ to the set of non-basic (which has now become $0$), and use the equation:
  \begin{displaymath}
    x_{33}=1-x_{13}-x_{23}.
  \end{displaymath}
  Using this we get a new tableau:
  \begin{displaymath}
    \begin{matrix}
      x_{11} & = & 1-x_{21} +x_{32}+x_{23}-x_{13}\\
      x_{12} & = & x_{21}+x_{23}-x_{32}\\
      x_{22} & = & 1-x_{21} -x_{23}\\
      x_{31} & = & x_{13}+x_{23}-x_{32}-x_{33}\\
      x_{33} & = & 1-x_{23}-x_{13}\\
      \hline
      \cc^T\xx & = & 3-2x_{13}-2x_{21}-3x_{23}+x_{32}.
    \end{matrix}
  \end{displaymath}
  All the non-basic variables have negative coefficients, except $x_{32}$.
  However, the constraint $x_{12}\geq 0$ still does not allow us to increase $x_{32}$ without changing any other non-basic variable.
  This suggests that we may have arrived at a maximum value for the objective function.
  Indeed, $x_{12}=x_{21}+x_{23}-x_{32}\geq 0$ implies that $x_{32}\leq x_{21}+x_{23}$ for every $\xx\in P(A,\bb)$, whence
  \begin{displaymath}
    \cc^T\xx=3-2x_{13}-2x_{21}-3x_{23}+x_{32}\leq 3-2x_{13}-x_{21}-2x_{23}\leq 3.
  \end{displaymath}
  Therefore $3$ is indeed a global maximum for the objective function, and is obtained uniquely at $x_{ij}=\delta_{ij}$.

  An alternative approach would be to induct $x_{32}$ into the set of basic variables, and remove $x_{12}$.
  Now the basic set is changed to $\{11,22,31,32,33\}$, but the basic feasible solution remains unchanged.
  This will result in the tableau:
  \begin{displaymath}
    \begin{matrix}
      x_{11} & = & 1-x_{12}+x_{32}+2x_{23}-x_{13}\\
      x_{22} & = & 1-x_{21} -x_{23}\\
      x_{31} & = & x_{12}+x_{13}-x_{21}-x_{33}\\
      x_{32} & = & x_{21}+x_{23}-x_{12}\\
      x_{33} & = & 1-x_{23}-x_{13}\\
      \hline
      \cc^T\xx & = & 3-2x_{13}-x_{21}-2x_{23}-x_{12}.
    \end{matrix}
  \end{displaymath}
  In this case, all the coefficients of the objective function are negative.
  Theorem~\eqref{equation:tableau-par} then implies that $x_{ij}=\delta_{ij}$ is the unique global maximum.
\end{example}

\end{document}
